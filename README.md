# voice-activity-detection
実装の大半は↓を参考にさせていただきました
- 「getUserMediaで音声を拾いリアルタイムで波形を出力する」https://qiita.com/mhagita/items/6c7d73932d9a207eb94d

## やってること
- マイクから音声を拾ってきて時間データとして描画する
- スペクトル分布(エネルギーの対数っぽい？)を取ってきて描画する
- スペクトル分布から計算した「声っぽさ」のスコアを描画する
  - [0, 2000Hz]のデータの和 - [4000Hz, 6000Hz]のデータの和　とかいう雑パラメータです
  - 物音や白色雑音はいい感じに除去できる気がします
- 大津の閾値を使って、スコアを「声あり」「声なし」に分ける閾値をオレンジ色で描画する
  - 上下のピーク時にサンプル点を追加して、クラスタリングを行わせてます(発話区間と無音区間が1:1に近いと性能が上がるかも)
  - データ点の数が膨大になるので、近くの2点をマージしてメモリを削減してます
